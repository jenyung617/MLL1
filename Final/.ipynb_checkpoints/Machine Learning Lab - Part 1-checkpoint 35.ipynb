{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Preprocessing and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "order = pd.read_csv('../data/Orders.csv') #, parse_dates = ['Order.Date'])\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "returns = pd.read_csv('../data/Returns.csv') #, parse_dates = ['Ship.Date'])\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming columns for better usage\n",
    "cols_order = order.columns.tolist()\n",
    "cols_order = [i.replace('.', '_').lower() for i in cols_order]\n",
    "order.columns = cols_order\n",
    "\n",
    "#Changing types for columns\n",
    "order.order_date = pd.to_datetime(order.order_date.astype(str), format = '%m/%d/%y')\n",
    "order.ship_date = pd.to_datetime(order.ship_date.astype(str), format = '%m/%d/%y')\n",
    "order['sales'] = order['sales'].str.replace('$', '').str.replace(',','').astype(float)\n",
    "order['profit'] = order['profit'].str.replace('$', '').str.replace(',','').astype(float)\n",
    "\n",
    "#Checking for missingness within the dataframe\n",
    "#orders.isna().sum() #works the same as below\n",
    "np.sum(order.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Quarters for Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seeing how many years of data we have\n",
    "order.order_date.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Setting the index for easy time series manipulation\n",
    "order = order.set_index('order_date')\n",
    "order['quarter'] = order.index.to_period('Q')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity Check - what is quantity looking at?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check - what is quantity actually counting? \n",
    "#Total quantity for order or quantity per item?\n",
    "check = order.loc[order['order_id'] == 'CA-2014-AB10015140-41954']\n",
    "check1 = order.loc[order['order_id'] == 'IN-2014-JR162107-41675']\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the code above, we can see that the quantity column is actually looking at the unique quantities of items for each sub-category. With that, we can sum the quantity by segment / categories / sub-categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seasonal Trend of Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Looking at total quantities per category - grouping by quarter to see if there are seasonality trends\n",
    "category = order.groupby(['quarter', 'category'])['quantity'].agg('sum').to_frame(name = 'quantity').reset_index()\n",
    "category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot below to show trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are issues where JSON cannot read time series, hence putting it into a string\n",
    "category.quarter = category.quarter.astype('str')\n",
    "\n",
    "#Using plotly express to see if there are any trends for inventory\n",
    "fig = px.line(category, x = 'quarter', y = 'quantity', color = 'category')\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title = 'Quarters',\n",
    "    yaxis_title = 'Quantity',\n",
    "    title={\n",
    "        'text': \"Looking at Inventory Seasonality\",\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'},\n",
    "    font = {'family': 'Arial',\n",
    "           'size': 12,\n",
    "           'color': 'rgb(31,33,36)'},\n",
    "    plot_bgcolor = 'rgba(0,0,0,0)',\n",
    "    paper_bgcolor = 'rgba(0,0,0,0)',\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeating for sub-category to see if there are any specific items that have more weight than others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_category = order.groupby(['quarter', 'sub_category'])[['quantity']]\\\n",
    "                .agg('sum').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot below to show trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are issues where JSON cannot read time series, hence putting it into a string\n",
    "sub_category.quarter = sub_category.quarter.astype('str')\n",
    "\n",
    "#Using plotly express to see if there are any trends for inventory\n",
    "fig = px.line(sub_category, x = 'quarter', y = 'quantity', color = 'sub_category')\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title = 'Quarters',\n",
    "    yaxis_title = 'Quantity',\n",
    "    title={\n",
    "        'text': \"Looking at Inventory Seasonality per Item\",\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'},\n",
    "    font = {'family': 'Arial',\n",
    "           'size': 12,\n",
    "           'color': 'rgb(31,33,36)'},\n",
    "    plot_bgcolor = 'rgba(0,0,0,0)',\n",
    "    paper_bgcolor = 'rgba(0,0,0,0)',\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally speaking, there is a seasonality trend seen, particularly in Q4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part a - Profit Lost due to Returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusting the **returns** data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming columns for better usage\n",
    "cols_returns = returns.columns.tolist()\n",
    "cols_returns = [i.replace(' ', '_').lower() for i in cols_returns]\n",
    "returns.columns = cols_returns\n",
    "\n",
    "#Sanity check - are all the values in returned 'Yes'?\n",
    "if len(returns.returned.unique()) == 1:\n",
    "    print('All values in returned are \\'Yes\\'.\\n')\n",
    "else:\n",
    "    print('Not all values in returned are \\'Yes\\'.\\nPlease check again.\\n')\n",
    "\n",
    "#Sanity check - are all order_id's unique?\n",
    "if returns.shape[0] == len(returns.order_id.unique()):\n",
    "    print('All order_id\\'s are unique.\\n')\n",
    "else:\n",
    "    print('Not all order_id\\'s are unique.\\nPleasecheck again\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "order_returns = pd.merge(order.reset_index(), returns, on = 'order_id')\n",
    "order_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noticed that region_y is created, even though both dataframes have the same column name. An inspection is done below to see whether all values between the two columns match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(order_returns['region_x'] == order_returns['region_y']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A total of 18 rows have mismatched regions. Taking a closer look at this columns below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_returns.loc[order_returns['region_x'] != order_returns['region_y']]\\\n",
    "    [['region_x', 'region_y']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Judging by the Canadian return locations, the original **returns** dataframe has more divided regions. Additionally, the three rows with *Central US* in the **order** dataframe appear to be *Western US* in the **returns** dataframe. For the purpose of this exercise,  *region_y* will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_returns = order_returns.set_index('order_date')\n",
    "order_returns['year'] = order_returns.index.to_period('Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_lost = order_returns.groupby('year').agg({'profit':'sum'})\n",
    "profit_lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total profit lost on returns across all years is ${round(profit_lost.sum()[0],2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part b - Customers Returning >1 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_df = order_returns.groupby(['order_id', 'customer_name'])['customer_name'].count().to_frame(name = 'count').reset_index().drop(columns = 'order_id')\n",
    "cust_1 = len(id_df.loc[id_df['count']>1])\n",
    "cust_5 = len(id_df.loc[id_df['count']>5])\n",
    "\n",
    "print(f'Customers returning more than once: {cust_1}')\n",
    "print(f'Customers returning more than 5 times: {cust_5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part c - Regions Likely to Return Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping by Region and looking at top 5 regions with highest returns\n",
    "returns.groupby('region')['returned'].count().sort_values(ascending = False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part d - Categories More Likely to be Returned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top Category to be returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_returns = order_returns.groupby('category').agg('sum')['quantity']\n",
    "cat_returns.groupby('category').sum().sort_values(ascending = False)[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top 5 Subcategories to be returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subcat_returns = order_returns.groupby('sub_category').agg('sum')['quantity']\n",
    "subcat_returns.groupby('sub_category').sum().sort_values(ascending = False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Machine Learning and Business Use Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a merged dataframe where if an order was not returned, adding No as attribute\n",
    "merged_df = pd.merge(order.reset_index(), returns, how = 'left', on = 'order_id')\n",
    "merged_df['returned'] = merged_df['returned'].replace(np.nan, 'No')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Further cleaning of merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the previous question's logic, *return regions* will be kept from the **returns** dataframe, whereas all other regions will be kept from the **order** dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.loc[merged_df.region_y.isna(), 'region_y'] = merged_df.region_x\n",
    "merged_df.rename(columns = {'region_y':'region'}, inplace = True)\n",
    "merged_df.drop(columns = 'region_x', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the process_time column in units of days\n",
    "merged_df['process_time'] = merged_df['ship_date'] - merged_df['order_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best practice suggests looking at return *rate* rather than *quantity*, as the *rate* is a normalized value. The steps below calculate the **return rate** for all returned products and assigns a 0 value to those that have not been returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataframe with total quantities of unique products\n",
    "total_by_prod_id = merged_df.groupby('product_id')[['quantity']].agg('sum').reset_index()\n",
    "\n",
    "\n",
    "#Creating a dataframe with quantities split by returned type\n",
    "returned_by_prod_id = merged_df.groupby(['product_id', 'returned'])[['quantity']].agg('sum').reset_index()\n",
    "\n",
    "\n",
    "#Merging dataframes total_by_prod_id and _returned_by_prod_id to calculate rate of return for each product\n",
    "prod_id_df = pd.merge(total_by_prod_id, returned_by_prod_id, how = 'right', on = 'product_id')\\\n",
    "            .rename(columns = {'quantity_x':'total_quantity', 'quantity_y':'returned_quantity'})\n",
    "prod_id_df['return_rate'] = prod_id_df['returned_quantity']/prod_id_df['total_quantity']\n",
    "prod_id_df.loc[prod_id_df.returned == 'No', ['return_rate', 'returned_quantity']] = 0\n",
    "\n",
    "\n",
    "#Creating a dataframe which shows product that have been returned\n",
    "mult_prod_id = prod_id_df.groupby('product_id').count()[['total_quantity']].reset_index()\n",
    "mult_prod_id = mult_prod_id[mult_prod_id.total_quantity>1]\n",
    "\n",
    "\n",
    "#With mult_prod_id, removing 'No' values from prod_id_df for items that have been returned\n",
    "prod_id_df = prod_id_df[~((prod_id_df['product_id'].isin(mult_prod_id.product_id)) & (prod_id_df['returned'] == 'No'))]\n",
    "\n",
    "\n",
    "#Rounding the return rate to 2 decimal points\n",
    "prod_id_df['return_rate'] = round(prod_id_df1['return_rate'],2)\n",
    "\n",
    "\n",
    "#Resulting dataframe with return_rate\n",
    "prod_id_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging prod_id_df with merged_df\n",
    "merged_df = pd.merge(merged_df, prod_id_df, on = 'product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
